{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Képi információ kezelése gépi tanuláskor\n",
    "\n",
    "Egy digitális képet tekinthetünk pixelekből álló rendezett struktúrának. A pixel a kép egy eleme, értéke a kép színmélységétől függ. A legegyszerűbb esetben fekete-fehér kép esetén az egyes pixelek értéke $0$ (fekete) vagy $1$ (fehér).\n",
    "\n",
    "Szürkeárnyalatos kép esetén az értéktartomány növelhető, például $[0;255]$-re, amely memóriafoglalása épp egy byte lesz. Ekkor a legkisebb érték jelenti a fekete színt, a legmagasabb érték pedig a fehéret. A fennmaradó $254$ szín pedig a szürke egy árnyalatát. Ez az úgynevezett 8-bites szürkeárnyalatos kép, hisz egy pixelhez tartozó intenzitás információ 8 biten, 1 byteon van eltárolva.\n",
    "\n",
    "Színes képek esetén a főszínekhez tartozó R, G és B csatorna értékeit szokás külön tárolni, így például egy pixelhez tartozhat egy 8 bites R, egy 8 bites G és egy 8 bites B csatorna, ennélfogva egy pixel színi információját 3 byteon, 24 biten írjuk le.\n",
    "\n",
    "Ha veszünk egy kicsinek számító, $640 \\times 480$-as színes képet, akkor a memóriában ehhez szükséges tárhely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921600\n"
     ]
    }
   ],
   "source": [
    "print(640*480*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persze ez a tömörítetlen esetet jelöli, a valóságban a fényképezett képek jól tömöríthetőek, minimális információveszteség mellett.\n",
    "\n",
    "Mi történne ha ezt a képet szeretnénk egy neurális hálózat bemeneteként megadni? Nyilván triviális megközelítés hogy minden leíró információt átadunk egy-egy bemeneti paraméterként, így a fentebb kapott érték lenne a bemeneti paraméterszám.\n",
    "\n",
    "Mivel ez a gyakorlatban kivitelezhetetlen, ezért fordulhatunk esetleg a tömörítés irányába. Persze itt inkább átalakítás jöhet szóba, hisz információvesztéskor a lényegi infókat mindenképp szeretnénk megtartani.\n",
    "\n",
    "Átalakíthatjuk például a képet szürkeárnyalatossá, ekkor (8-bit esetén) egyetlen byteon tárolnánk a színi információkat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(640*480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harmadára csökkent a paraméterszám, de még mindig messze nagyobb, mint ami kezelhető lenne. Megoldás lehet a kép méretének csökkentése, azaz a kép zsugorítása:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(128*96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A megvalósíthatóságért jelentős információvesztéssel fizetünk (TODO: ha egyszer könyvet írok, ez belekerül :D).\n",
    "\n",
    "Megjegyzés: a gépi tanulás hosszas történelme során a kutatók kifejlesztettek különféle elemzésen módszereket az adatok információtartó transzformációjára, amellyel kisebb paraméterszám érhető el, lásd pl. főkomponens analízis.\n",
    "\n",
    "### ImageDataGenerator\n",
    "\n",
    "A következőekben áttekintjük a Keras által biztosított eszközöket kifejezetten képi bemenetek esetére, és megvizsgáljuk a hatékonyságot és lehetséges megoldási módszereket.\n",
    "\n",
    "A Kerasban a középpontban az ImageDataGenerator osztály áll:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Projects\\deeplearning\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Részleteiben lásd: https://keras.io/preprocessing/image/\n",
    "\n",
    "A példánynál meghatározható, hogy a betöltött képeken esetleg milyen átalakításokat végezzen (lásd kicsit később mint *data augmentation*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\deeplearning\\venv\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:1460: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255, featurewise_std_normalization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az mindig jó ötlet, ha az adatokat normalizáljuk és centralizáljuk, így a hálózat gyorsabban fog tanulni.\n",
    "\n",
    "A generátor persze csak azt mondja meg hogy mi történjen az adatokkal, maguk az adatok másutt vannak definiálva. Képek esetén például lehetséges tárolni őket mint külön állományok (értsd: képek, könyvtárakban). Más lehetőség, ha felépítünk belőlük egy nagy bináris állomány, amelyben multidimenzionális tömbben tároljuk a különböző képeket, és a címkéiket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Dataset\n",
    "\n",
    "Jelen példához mi az MNIST adathalmazt fogjuk felhasználni. Ebben az adatbázisban kézzel írott számjegyek találhatóak, megcímkézve a hozzájuk tartozó numerikus értékkel, lásd: https://en.wikipedia.org/wiki/MNIST_database.\n",
    "\n",
    "Ezen adathalmazon többféle érdekes kísérlet elvégezhető, de a gyakorlatban is hasznos megoldás születhet ha OCR (Optical Character Recognition) megoldást készítenénk számokra: a bemeneti kép alapján egy többosztályú klasszifikáció kimenete lehet a felismert számjegy.\n",
    "\n",
    "A datasetet ZIP állományként feltöltöttem a weboldalra. A ZIPen belül az egyes alkönyvtárakban (0, 1, 2, ..., 9) az egyes szájegyekhez tartozó képek találhatóak.\n",
    "\n",
    "*Megjegyzés*: a Keras készítői gondolnak a kísérletezőkre, így a *keras.datasets* package alatt többféle dataset is megtalálható, például az MNIST is, amely esetén a *mnist.load_data()* segítségével betölthetőek a tanítóminták."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"mnist/trainingSet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izgalmas kérdés, hogy összesen - illetve osztályonként hány tanítómintánk van (lásd https://docs.python.org/3/library/os.html#os.walk):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4132, 4684, 4177, 4351, 4072, 3795, 4137, 4401, 4063, 4188]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(files) for root, dirs, files in os.walk(\"mnist/trainingSet\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mnist/trainingSet: 0',\n",
       " 'mnist/trainingSet\\\\0: 4132',\n",
       " 'mnist/trainingSet\\\\1: 4684',\n",
       " 'mnist/trainingSet\\\\2: 4177',\n",
       " 'mnist/trainingSet\\\\3: 4351',\n",
       " 'mnist/trainingSet\\\\4: 4072',\n",
       " 'mnist/trainingSet\\\\5: 3795',\n",
       " 'mnist/trainingSet\\\\6: 4137',\n",
       " 'mnist/trainingSet\\\\7: 4401',\n",
       " 'mnist/trainingSet\\\\8: 4063',\n",
       " 'mnist/trainingSet\\\\9: 4188']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"{}: {}\".format(root, len(files)) for root, dirs, files in os.walk(\"mnist/trainingSet\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az a helyzet, hogy a különböző mintákból különböző számú tanítóminta áll rendelkezésre. Ez semmiképp sem jó! Mindenképp úgy kell kialakítani a megoldásunkat, hogy a tanítás során az egyes epochokban osztályonként mindig azonos számú mintával tanítsunk. Minden más esetben torzul a modell.\n",
    "\n",
    "Több megoldás lehetséges:\n",
    "- növelem a tanítómintáim számát úgy, hogy azonos számot kapjak (:));\n",
    "- csökkentem a tanítóminták számát a minimumra;\n",
    "- epochonként véletlenszerűen veszek ki fix, kis számú mintát;\n",
    "- növelem a tanítóminták számát generált adatokkal.\n",
    "\n",
    "Valójában mindegyik megoldás alkalmazott a gyakorlatban, szóban megbeszéljük hogy miért. Mi, ezen a laboron a legegyszerűbb irányba megyünk, és csökkentjük az egyes klasszokhoz tartozó tanítóminták számát addig, amíg mindenütt azonos számú minta nem lesz.\n",
    "\n",
    "A kidolgozott megoldás alapötlete az, hogy az egyes könyvtárakból random törlünk annyi képet, amennyi a minimálistól való eltérés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_len = min([len(files) for root, dirs, files in os.walk(\"mnist/trainingSet\")][1:])\n",
    "min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(\"mnist/trainingSet\"):\n",
    "    if (len(files) == 0):\n",
    "        continue\n",
    "    del_count = len(files)-min_len\n",
    "    random.shuffle(files)\n",
    "    for f in files[:del_count]:\n",
    "        os.remove(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nézzük sikerült-e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mnist/trainingSet: 0',\n",
       " 'mnist/trainingSet\\\\0: 3795',\n",
       " 'mnist/trainingSet\\\\1: 3795',\n",
       " 'mnist/trainingSet\\\\2: 3795',\n",
       " 'mnist/trainingSet\\\\3: 3795',\n",
       " 'mnist/trainingSet\\\\4: 3795',\n",
       " 'mnist/trainingSet\\\\5: 3795',\n",
       " 'mnist/trainingSet\\\\6: 3795',\n",
       " 'mnist/trainingSet\\\\7: 3795',\n",
       " 'mnist/trainingSet\\\\8: 3795',\n",
       " 'mnist/trainingSet\\\\9: 3795']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"{}: {}\".format(root, len(files)) for root, dirs, files in os.walk(\"mnist/trainingSet\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nézzünk meg pár mintát a maradék képekből:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ebben a példafeladatban nem fogunk validációs halmazt leválasztani: ha szükségünk lenne rá, egészen egyszerűen külön könyvtárba másolt képekkel meg tudnánk oldani."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A definiált generátornak van egy *.flow_from_directory()* metódusa, amely segítségével a könyvtár egyes elemeit el tudjuk érni: https://keras.io/preprocessing/image/#flow_from_directory\n",
    "\n",
    "<pre>flow_from_directory(directory, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', follow_links=False, subset=None, interpolation='nearest')</pre>\n",
    "\n",
    "Azaz, a képek betöltéskor átméretezhetőek (*target_size*), színmód változtatható (*color_mode*), valamint további funkciók is elérhetőek. A Keras tehát sokat segít abban, hogy a képek kezelésével ne (se) kelljen foglalkoznunk.\n",
    "\n",
    "Mindezt pedig a modellnek a *.fit_generator()* metódusán keresztül adjuk át az eddig használt *.fit()* helyett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_gen.flow_from_directory(\"trainingSet\",\n",
    "                                           target_size=(28, 28),\n",
    "                                           batch_size=512,\n",
    "                                           color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hálózati architektúra\n",
    "\n",
    "Készítsünk architektúrát az eddig ismert elemekből. A bemeneti elemek száma $28 \\times 28$, hisz az egyes pixelek kezelhetőek mint különálló leírók, szerializálva bemenetnek átadhatóak. A képek szürkeárnyalatosak, színi információt nem viszünk magunkkal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az adatok háromdimenziós tömbként jönnek ($28 \\times 28 \\times 1$), míg az *Input* réteg persze egydimenziós vektort vár: kezdjük az egész modellt egy *Reshape* réteggel, ami szerializálja a bemenetként kapott tömböt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Reshape((784, ), input_shape=(28, 28, 1)))\n",
    "model.add(Dense(784, input_shape=(784, )))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(400))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_data,\n",
    "                    epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tanítás lassú: **SOK** a paraméter!\n",
    "\n",
    "Hogy lehet a paraméterek számán csökkenteni? Valójában ahogy fentebb a summary is mutatja, a nagy paraméterszámot a bemeneti 784 paraméter okozza. A tanítható paraméterek számát az első rétegben ugyanis a bemenetként kapott értékek és a neuronok számának szorzata adja: $784 \\times 784$, plusz az eltolás értékekkel együtt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "784*784+784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persze ezen lehet segíteni, ha a neuronszámot csökkentjük... de ezt már megtanultuk, hogy rossz megközelítés. Már ez a \"sekély\" hálózat is pontatlan, de mélyebb, azaz több rejtett rétegű hálózattal a paraméterszám is nő, a számításigény (és a memóriaköltség) megnő, a tanítás lassul.\n",
    "\n",
    "És ennél a feladatnál 28 pixel széles és magas miniatűr képekről beszélünk!\n",
    "\n",
    "Ez egy fontos probléma, amely rendhagyó megoldást kíván: következő alkalommal alaposan átnézzük!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teljesítmény\n",
    "\n",
    "Betanítást követően azt látjuk, hogy a teljesítmény alacsony, próbálkozzunk meg a klasszifikációs pontosság javításával.\n",
    "\n",
    "Az előző hálózat elég \"hasraütés-szerűen\" került kialakításra, próbáljunk meg mélyebb struktúrát kialakítani."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((784, ), input_shape=(28, 28, 1)))\n",
    "model.add(Dense(784, input_shape=(784, )))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(500))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(500))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(200))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(200))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(50))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(50))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_gen.flow_from_directory(\"trainingSet\",\n",
    "                                           target_size=(28, 28),\n",
    "                                           batch_size=512,\n",
    "                                           color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_data,\n",
    "                    epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Színes képek\n",
    "\n",
    "Amennyiben színes képeket kap bemenetként a hálózat, azok 3D mátrixként érkeznek, mint $H \\times W \\times C$, ahol az első két dimenzió a kép méretével egyezik meg, míg a harmadik hossza $3$. Ez reprezentálja ugyanis az RGB színmód $3$ csatornáját, a <span style=\"color: red\">vörös</span>, <span style=\"color: green\">zöld</span>, <span style=\"color: blue\">kék</span> színek intenzitását. E három főszín keverékéből állítjuk elő a többi színt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ennek illusztrálására egy másik problémát keresünk, a klasszikus ***Cats Vs Dogs*** challenge megoldásával próbálkozunk meg - klasszikus eszközökkel. A dataset zippelve elérhető a weboldalon.\n",
    "\n",
    "Első feladat: ellenőrizzük a minták számát!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"{}: {}\".format(root, len(files)) for root, dirs, files in os.walk(\"catsvsdogs\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itt eleve adott a minták azonos száma, nincs dolgunk.\n",
    "\n",
    "Esetleg nézzünk pár mintaképet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2)\n",
    "i=0\n",
    "for root, dirs, files in os.walk(\"catsvsdogs\"):\n",
    "    if (len(files) <= 1):\n",
    "        continue\n",
    "    axs[int(i/2)][i%2].imshow(mpimg.imread(os.path.join(root, random.choice(files))))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Változóak a méretek, mindenképp át kell méretezni a bemenetre kerülő képeket. További nehezítés, hogy a bemenet mérete fix kell hogy legyen, itt a képek arányában is megfigyelhető különbség: van fekvő és álló kép is.\n",
    "\n",
    "Definiáljuk a generátort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 64\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./255, featurewise_std_normalization=True)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\"catsvsdogs\\\\training_set\",\n",
    "                                           target_size=(imsize, imsize),\n",
    "                                           class_mode='binary',\n",
    "                                           batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tesztelésre (validálásra) is lehet külön generátort definiálni, ebbe az irányba induljunk el:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255, featurewise_std_normalization=True)\n",
    "\n",
    "test_data = train_gen.flow_from_directory(\"catsvsdogs\\\\test_set\",\n",
    "                                           target_size=(imsize, imsize),\n",
    "                                           class_mode='binary',\n",
    "                                           batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lévén hogy két osztály van csak, bináris klasszifikációként is definiálhatjuk a feladatot. A problémától és a konkrét bemenetektől függően persze lehet hogy célszerű 2D vektor kimenetű vektort adni. Utóbbi esetben a modell képes arra is, hogy a nem kutya és nem macska objektumokat is helyesen jelezze.\n",
    "\n",
    "Definiáljuk a struktúrát:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_num = imsize*imsize*3\n",
    "\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Reshape((param_num, ), input_shape=(imsize, imsize, 3)))\n",
    "model.add(Dense(4000, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(4000, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_data,\n",
    "                    epochs=20,\n",
    "                    validation_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folytatás innen, következő alkalommal!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
